nohup: ignoring input
Using device: cuda
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.30it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.28it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]
Traceback (most recent call last):
  File "/home/zhiyu2/guangliang/SuperficialMoralSelfCorrection/mechanism/run_inference2.py", line 247, in <module>
    tokenizer, llm = init_model(args)
                     ^^^^^^^^^^^^^^^^
  File "/home/zhiyu2/guangliang/SuperficialMoralSelfCorrection/mechanism/utils.py", line 87, in init_model
    return tokenizer, model.to(device)
                      ^^^^^^^^^^^^^^^^
  File "/home/zhiyu2/miniconda3/envs/zimo/lib/python3.11/site-packages/transformers/modeling_utils.py", line 2883, in to
    return super().to(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhiyu2/miniconda3/envs/zimo/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1174, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/zhiyu2/miniconda3/envs/zimo/lib/python3.11/site-packages/torch/nn/modules/module.py", line 780, in _apply
    module._apply(fn)
  File "/home/zhiyu2/miniconda3/envs/zimo/lib/python3.11/site-packages/torch/nn/modules/module.py", line 805, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "/home/zhiyu2/miniconda3/envs/zimo/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1160, in convert
    return t.to(
           ^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 500.00 MiB. GPU 0 has a total capacity of 44.55 GiB of which 170.25 MiB is free. Process 1158933 has 8.82 GiB memory in use. Process 1781894 has 8.81 GiB memory in use. Including non-PyTorch memory, this process has 26.74 GiB memory in use. Of the allocated memory 26.49 GiB is allocated by PyTorch, and 992.00 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
